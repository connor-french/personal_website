{"title":"Sonification for data communication","markdown":{"yaml":{"title":"Sonification for data communication","author":"Connor French","description":"Sonification as a cool way to understand data and make data communication more accessible.","date":"2021-04-19","aliases":["../sonification/"],"categories":["R","Research","Data Visualization","GCDI"],"image":"featured.png"},"headingText":"function to generate data","containsRefs":false,"markdown":"\n\n[Originally published on GC Digital Initiatives](https://digitalfellows.commons.gc.cuny.edu/2021/04/19/sonification-for-data-communication/)\n\n```{r setup, message = FALSE, echo=FALSE}\nlibrary(sonify)\nlibrary(tidyverse)\nlibrary(here)\n\ntheme_set(theme_minimal())\ntheme_update(axis.title = element_text(size = 16))\n\nknitr::opts_chunk$set(fig.width = 5, fig.height = 4, fig.align = \"center\")\n```\n\nA few weeks ago my partner shared a [TED Talk](https://www.youtube.com/watch?v=-hY9QSdaReY) with me that changed how I conceptualize data communication. In it [Dr. Wanda Diaz Merced](https://www.ted.com/speakers/wanda_diaz_merced), an astronomer who lost her eyesight in her early twenties, discusses her journey back into science after this setback. A crucial technique helped her interpret hefty astronomy data sets- sonification. [Sonification turns data into sound](https://handbook.floeproject.org/sonification). It is analogous to data visualization, where both methods aim to communicate patterns and relationships within data clearly and efficiently. Not only did sonification make data accessible for Dr. Merced, it helped her uncover patterns obscured by visualizing graphs and charts.\n\nThere are [quite a few applications](https://www.techfak.uni-bielefeld.de/ags/ami/publications/media/Hermann2002-SFE.pdf) for sonification. The bing you get when an email lands in your inbox is one familiar example. The recognizable noise conveys a simple piece of information without requiring you to be sitting at the computer or staring at your phone. Representing large data sets gets a little more complicated.\n\nAudio has multiple dimensions that can be exploited to represent information, including:\n\n-   pitch\\\n-   loudness\\\n-   duration\\\n-   spatial arrangement (e.g. stereo panning)\n\nThese can be combined to represent multiple data dimensions or used interchangeably to represent the same data in a new way. Best practices are still being formed and are often context-dependent on the user, but a great resource for the latest practices is the [Floe Inclusive Learning Design Handbook](https://handbook.floeproject.org/sonification).\n\nA particular application that is relevant for folks who want to increase the accessibility of their publications is to sonify their existing data visualizations. Below are a few common examples. Each example is a visualization, followed by the sonification. I have chosen to represent values on the y-axis as changes in pitch, while time indicates change along the x-axis. To emphasize the change in time along the x-axis, I have added short white noise pulses for each data point along the x-axis. The listener is \"reading\" the plot from left to right.\n\n```{r, echo=FALSE}\ngenerate_data <- function(n_obs = 100, \n                          min_x = 0, \n                          max_x = 10, \n                          beta = 1, \n                          error_sigma = 1, \n                          is_exponential = FALSE,\n                          exponent = 2,\n                          alpha = 1) {\n  x <- runif(n_obs, min_x, max_x)\n  e <- rnorm(n_obs, 0, error_sigma)\n  \n  if (is_exponential == TRUE) {\n    y <- alpha*x^(exponent*beta) + e\n  } else y <- x*beta + e\n  \n  \n  df <- tibble(predictor = x, response = y)\n  \n  return(df)\n}\n```\n\nA common data visualization technique for single variables is the histogram. These emphasize the distribution of the variable under consideration. Below, I've simulated data representing my mood 15 minutes before eating dinner over the last several weeks.\n\n<br>\n\n```{r, echo=FALSE, fig.cap=\"A histogram representing the distribution of mood score values.\"}\nset.seed(62)\n\nunivariate_data <- generate_data()\n\nresponse_hist <- univariate_data %>% \n  filter(response > 0) %>% \n  ggplot(aes(x = response)) +\n  geom_histogram(bins = 20, fill = \"skyblue\", color = \"black\") +\n  labs(x = \"Mood score\",\n       y = \"Frequency\")\n\nresponse_hist\n```\n\n```{r, echo=FALSE, eval=FALSE}\nggsave(filename = here(\"figures\", \"histogram.png\"), \n       plot = response_hist, width = 5, height = 4, units = \"in\")\n```\n\n```{r, eval=FALSE, echo=FALSE}\n# get histogram count data for sonification\nhist_data <- ggplot_build(response_hist)$data[[1]]\n\nsound_univariate <- sonify::sonify(y = hist_data$count, \n                        duration = 10,\n                        pulse_len = 0.1)\n\ntuneR::writeWave(sound_univariate, here(\"audio\", \"sound_univariate.wav\"))\n```\n\n<br>\n\n<html>\n\n<audio controls>\n\n<source src=\"sound_univariate.wav\" type=\"audio/wav\">\n\n</audio>\n\n</html>\n\n<br> <br> Notice how the pitch oscillates in a similar manner to the shape of the distribution and the pulses are evenly spaced, representing the bins of the distribution!\n\n<br> Now, let's sonify two variables at once! The visualization below is a scatterplot, a common technique for two continuous variables. The data is simulated to represent how much I crave a burger depending on how hungry I am.\\\n<br>\n\n```{r, echo=FALSE, fig.cap=\"A scatterplot representing a linear relationship between two variables. Hunger level on the x axis and burger craving strength on the y axis\"}\nset.seed(7485)\n\nlinear_data <- generate_data(n_obs = 50, beta = 1.2, error_sigma = 1, is_exponential = FALSE)\n\nlinear_plot <- linear_data %>%\n  ggplot(aes(x = predictor, y = response)) +\n  geom_point(fill = \"skyblue\", color = \"black\", size = 3, shape = 21) +\n  labs(x = \"Hunger level\", y = \"Burger craving strength\")\n\nlinear_plot\n```\n\n```{r, echo=FALSE, eval=FALSE}\nggsave(filename = here(\"figures\", \"linear_scatter.png\"), \n       plot = linear_plot, width = 5, height = 4, units = \"in\")\n```\n\n```{r, echo=FALSE, eval=FALSE}\nsound_linear <- sonify::sonify(x = linear_data$predictor, \n                        y = linear_data$response, \n                        duration = 10,\n                        pulse_len = 0.1)\n\ntuneR::writeWave(sound_linear, here(\"audio\", \"sound_linear.wav\"))\n```\n\n<br>\n\n<html>\n\n<audio controls>\n\n<source src=\"sound_linear.wav\" type=\"audio/wav\">\n\n</audio>\n\n</html>\n\n<br> <br>\n\nNotice how the pitch increase with time, but there are oscillations which represent error around a perfect linear relationship. Also notice how the pulses are less even- the points aren't evenly distributed on the x-axis. Pretty cool!\n\n<br>\n\nThe final visualization I'll present is an exponential relationship between two variables. The simulated data in this scenario represents my craving for a big ol' plate of nachos dependent on how hungry I am.\n\n<br>\n\n```{r, echo=FALSE, fig.cap=\"A scatterplot representing an exponential relationship between two variables. Hunger level on the x axis and burger craving strength on the y axis\"}\nexpnt <- 2\n\nset.seed(9999)\n\nexponential_data <- generate_data(is_exponential = TRUE, exponent = expnt)\n\nexponential_plot <- exponential_data %>%\n  ggplot(aes(x = predictor, y = response)) +\n  geom_point(fill = \"skyblue\", color = \"black\", size = 3, shape = 21) +\n  labs(x = \"Hunger level\", y = \"Nachos craving strength\")\n\nexponential_plot\n```\n\n```{r, echo=FALSE, eval=FALSE}\nggsave(filename = here(\"figures\", \"exponential_scatter.png\"), \n       plot = exponential_plot, width = 5, height = 4, units = \"in\")\n```\n\n```{r, eval=FALSE, echo=FALSE}\nexponential_sound <- sonify::sonify(x = exponential_data$predictor, \n                        y = exponential_data$response, \n                        duration = 10,\n                        pulse_len = 0.1)\n\ntuneR::writeWave(exponential_sound, here(\"audio\", \"sound_exponential.wav\"))\n```\n\n<br>\n\n<html>\n\n<audio controls>\n\n<source src=\"sound_exponential.wav\" type=\"audio/wav\">\n\n</audio>\n\n</html>\n\n<br> <br>\n\nIn this case, the pitch increases, well, exponentially! In addition, the points are tighter together- The pitch oscillates less than the linearly related data. My nacho cravings are pretty consistent.\n\n<br>\n\nThese are just a few ways sonification can be incorporated into your data communication and exploration arsenal. Besides making data more accessible to those who are blind or low vision, sonification opens up another avenue of data exploration to uncover patterns not evident in a visßual medium. Dr. Merced was able to [hear a distinct frequency pattern](https://youtu.be/-hY9QSdaReY?t=287) not evident from a chart that led her to discover that star formation likely plays an important part in supernova explosions! Sighted astronomers now use sonfication as a complement to visualization to investigate their data. If you would like to take a crack at sonification yourself, there are a [variety](https://osf.io/vgaxh/wiki/Resources/) of [resources](https://jarednielsen.medium.com/data-sonification-and-web-scraping-with-node-js-and-tone-js-eaf2cd35a000). The sonifications for this post were created using the R package [sonify](https://cran.r-project.org/web/packages/sonify/index.html), which is a straightforward interface that will get you there quickly, without much overhead. You can find the R code for this blog post [here](https://raw.githubusercontent.com/connor-french/sonification_ttt_post/main/sonification_ttt_post.Rmd).\n\n<br>\n\nThose of us at the [Graduate Center Digital Initiatives](https://gcdi.commons.gc.cuny.edu/) strive to make interactions with digital media more accessible. We provide a variety of resources to take advantage of digital tools in your research. In addition, we provide community and support with the [Digital Fellows](https://digitalfellows.commons.gc.cuny.edu/), so I encourage you to take a look and connect with us!\n","srcMarkdownNoYaml":"\n\n[Originally published on GC Digital Initiatives](https://digitalfellows.commons.gc.cuny.edu/2021/04/19/sonification-for-data-communication/)\n\n```{r setup, message = FALSE, echo=FALSE}\nlibrary(sonify)\nlibrary(tidyverse)\nlibrary(here)\n\ntheme_set(theme_minimal())\ntheme_update(axis.title = element_text(size = 16))\n\nknitr::opts_chunk$set(fig.width = 5, fig.height = 4, fig.align = \"center\")\n```\n\nA few weeks ago my partner shared a [TED Talk](https://www.youtube.com/watch?v=-hY9QSdaReY) with me that changed how I conceptualize data communication. In it [Dr. Wanda Diaz Merced](https://www.ted.com/speakers/wanda_diaz_merced), an astronomer who lost her eyesight in her early twenties, discusses her journey back into science after this setback. A crucial technique helped her interpret hefty astronomy data sets- sonification. [Sonification turns data into sound](https://handbook.floeproject.org/sonification). It is analogous to data visualization, where both methods aim to communicate patterns and relationships within data clearly and efficiently. Not only did sonification make data accessible for Dr. Merced, it helped her uncover patterns obscured by visualizing graphs and charts.\n\nThere are [quite a few applications](https://www.techfak.uni-bielefeld.de/ags/ami/publications/media/Hermann2002-SFE.pdf) for sonification. The bing you get when an email lands in your inbox is one familiar example. The recognizable noise conveys a simple piece of information without requiring you to be sitting at the computer or staring at your phone. Representing large data sets gets a little more complicated.\n\nAudio has multiple dimensions that can be exploited to represent information, including:\n\n-   pitch\\\n-   loudness\\\n-   duration\\\n-   spatial arrangement (e.g. stereo panning)\n\nThese can be combined to represent multiple data dimensions or used interchangeably to represent the same data in a new way. Best practices are still being formed and are often context-dependent on the user, but a great resource for the latest practices is the [Floe Inclusive Learning Design Handbook](https://handbook.floeproject.org/sonification).\n\nA particular application that is relevant for folks who want to increase the accessibility of their publications is to sonify their existing data visualizations. Below are a few common examples. Each example is a visualization, followed by the sonification. I have chosen to represent values on the y-axis as changes in pitch, while time indicates change along the x-axis. To emphasize the change in time along the x-axis, I have added short white noise pulses for each data point along the x-axis. The listener is \"reading\" the plot from left to right.\n\n```{r, echo=FALSE}\n# function to generate data\ngenerate_data <- function(n_obs = 100, \n                          min_x = 0, \n                          max_x = 10, \n                          beta = 1, \n                          error_sigma = 1, \n                          is_exponential = FALSE,\n                          exponent = 2,\n                          alpha = 1) {\n  x <- runif(n_obs, min_x, max_x)\n  e <- rnorm(n_obs, 0, error_sigma)\n  \n  if (is_exponential == TRUE) {\n    y <- alpha*x^(exponent*beta) + e\n  } else y <- x*beta + e\n  \n  \n  df <- tibble(predictor = x, response = y)\n  \n  return(df)\n}\n```\n\nA common data visualization technique for single variables is the histogram. These emphasize the distribution of the variable under consideration. Below, I've simulated data representing my mood 15 minutes before eating dinner over the last several weeks.\n\n<br>\n\n```{r, echo=FALSE, fig.cap=\"A histogram representing the distribution of mood score values.\"}\nset.seed(62)\n\nunivariate_data <- generate_data()\n\nresponse_hist <- univariate_data %>% \n  filter(response > 0) %>% \n  ggplot(aes(x = response)) +\n  geom_histogram(bins = 20, fill = \"skyblue\", color = \"black\") +\n  labs(x = \"Mood score\",\n       y = \"Frequency\")\n\nresponse_hist\n```\n\n```{r, echo=FALSE, eval=FALSE}\nggsave(filename = here(\"figures\", \"histogram.png\"), \n       plot = response_hist, width = 5, height = 4, units = \"in\")\n```\n\n```{r, eval=FALSE, echo=FALSE}\n# get histogram count data for sonification\nhist_data <- ggplot_build(response_hist)$data[[1]]\n\nsound_univariate <- sonify::sonify(y = hist_data$count, \n                        duration = 10,\n                        pulse_len = 0.1)\n\ntuneR::writeWave(sound_univariate, here(\"audio\", \"sound_univariate.wav\"))\n```\n\n<br>\n\n<html>\n\n<audio controls>\n\n<source src=\"sound_univariate.wav\" type=\"audio/wav\">\n\n</audio>\n\n</html>\n\n<br> <br> Notice how the pitch oscillates in a similar manner to the shape of the distribution and the pulses are evenly spaced, representing the bins of the distribution!\n\n<br> Now, let's sonify two variables at once! The visualization below is a scatterplot, a common technique for two continuous variables. The data is simulated to represent how much I crave a burger depending on how hungry I am.\\\n<br>\n\n```{r, echo=FALSE, fig.cap=\"A scatterplot representing a linear relationship between two variables. Hunger level on the x axis and burger craving strength on the y axis\"}\nset.seed(7485)\n\nlinear_data <- generate_data(n_obs = 50, beta = 1.2, error_sigma = 1, is_exponential = FALSE)\n\nlinear_plot <- linear_data %>%\n  ggplot(aes(x = predictor, y = response)) +\n  geom_point(fill = \"skyblue\", color = \"black\", size = 3, shape = 21) +\n  labs(x = \"Hunger level\", y = \"Burger craving strength\")\n\nlinear_plot\n```\n\n```{r, echo=FALSE, eval=FALSE}\nggsave(filename = here(\"figures\", \"linear_scatter.png\"), \n       plot = linear_plot, width = 5, height = 4, units = \"in\")\n```\n\n```{r, echo=FALSE, eval=FALSE}\nsound_linear <- sonify::sonify(x = linear_data$predictor, \n                        y = linear_data$response, \n                        duration = 10,\n                        pulse_len = 0.1)\n\ntuneR::writeWave(sound_linear, here(\"audio\", \"sound_linear.wav\"))\n```\n\n<br>\n\n<html>\n\n<audio controls>\n\n<source src=\"sound_linear.wav\" type=\"audio/wav\">\n\n</audio>\n\n</html>\n\n<br> <br>\n\nNotice how the pitch increase with time, but there are oscillations which represent error around a perfect linear relationship. Also notice how the pulses are less even- the points aren't evenly distributed on the x-axis. Pretty cool!\n\n<br>\n\nThe final visualization I'll present is an exponential relationship between two variables. The simulated data in this scenario represents my craving for a big ol' plate of nachos dependent on how hungry I am.\n\n<br>\n\n```{r, echo=FALSE, fig.cap=\"A scatterplot representing an exponential relationship between two variables. Hunger level on the x axis and burger craving strength on the y axis\"}\nexpnt <- 2\n\nset.seed(9999)\n\nexponential_data <- generate_data(is_exponential = TRUE, exponent = expnt)\n\nexponential_plot <- exponential_data %>%\n  ggplot(aes(x = predictor, y = response)) +\n  geom_point(fill = \"skyblue\", color = \"black\", size = 3, shape = 21) +\n  labs(x = \"Hunger level\", y = \"Nachos craving strength\")\n\nexponential_plot\n```\n\n```{r, echo=FALSE, eval=FALSE}\nggsave(filename = here(\"figures\", \"exponential_scatter.png\"), \n       plot = exponential_plot, width = 5, height = 4, units = \"in\")\n```\n\n```{r, eval=FALSE, echo=FALSE}\nexponential_sound <- sonify::sonify(x = exponential_data$predictor, \n                        y = exponential_data$response, \n                        duration = 10,\n                        pulse_len = 0.1)\n\ntuneR::writeWave(exponential_sound, here(\"audio\", \"sound_exponential.wav\"))\n```\n\n<br>\n\n<html>\n\n<audio controls>\n\n<source src=\"sound_exponential.wav\" type=\"audio/wav\">\n\n</audio>\n\n</html>\n\n<br> <br>\n\nIn this case, the pitch increases, well, exponentially! In addition, the points are tighter together- The pitch oscillates less than the linearly related data. My nacho cravings are pretty consistent.\n\n<br>\n\nThese are just a few ways sonification can be incorporated into your data communication and exploration arsenal. Besides making data more accessible to those who are blind or low vision, sonification opens up another avenue of data exploration to uncover patterns not evident in a visßual medium. Dr. Merced was able to [hear a distinct frequency pattern](https://youtu.be/-hY9QSdaReY?t=287) not evident from a chart that led her to discover that star formation likely plays an important part in supernova explosions! Sighted astronomers now use sonfication as a complement to visualization to investigate their data. If you would like to take a crack at sonification yourself, there are a [variety](https://osf.io/vgaxh/wiki/Resources/) of [resources](https://jarednielsen.medium.com/data-sonification-and-web-scraping-with-node-js-and-tone-js-eaf2cd35a000). The sonifications for this post were created using the R package [sonify](https://cran.r-project.org/web/packages/sonify/index.html), which is a straightforward interface that will get you there quickly, without much overhead. You can find the R code for this blog post [here](https://raw.githubusercontent.com/connor-french/sonification_ttt_post/main/sonification_ttt_post.Rmd).\n\n<br>\n\nThose of us at the [Graduate Center Digital Initiatives](https://gcdi.commons.gc.cuny.edu/) strive to make interactions with digital media more accessible. We provide a variety of resources to take advantage of digital tools in your research. In addition, we provide community and support with the [Digital Fellows](https://digitalfellows.commons.gc.cuny.edu/), so I encourage you to take a look and connect with us!\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"toc-depth":3,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.549","editor":"visual","theme":{"light":"minty","dark":"cyborg"},"title-block-banner":true,"toc-title":"Table of contents","toc-location":"left","page-layout":"article","citation":true,"comments":{"utterances":{"repo":"connor-french/connorfrench"}},"title":"Sonification for data communication","author":"Connor French","description":"Sonification as a cool way to understand data and make data communication more accessible.","date":"2021-04-19","aliases":["../sonification/"],"categories":["R","Research","Data Visualization","GCDI"],"image":"featured.png"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}